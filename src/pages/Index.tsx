import { useState } from "react";
import { Loader2 } from "lucide-react";
import RecordingInterface from "@/components/RecordingInterface";
import SpeakerSelection from "@/components/SpeakerSelection";
import AnalysisResults from "@/components/AnalysisResults";
import AudioInput from "@/components/AudioInput";
import { api, handleApiError } from "@/utils/api";

type AppState = 'input' | 'recording' | 'processing' | 'speaker-selection' | 'results';

const Processing = ({ message }: { message: string }) => (
  <div className="min-h-screen bg-white page-container">
    <div className="flex flex-col items-center justify-center space-y-6 animate-fade-in text-center min-h-[50vh]">
      <div className="w-20 h-20 bg-blue-50 rounded-full flex items-center justify-center">
        <Loader2 className="w-12 h-12 text-blue-600 animate-spin" />
      </div>
      <p className="text-body text-gray-700">
        {message}
      </p>
    </div>
  </div>
);

const Index = () => {
  const [appState, setAppState] = useState<AppState>('input');
  const [processingMessage, setProcessingMessage] = useState<string>('');
  const [recordedData, setRecordedData] = useState<any>(null);
  const [userName, setUserName] = useState<string>('');
  const [participantCount, setParticipantCount] = useState<number>(2);
  const [selectedSpeaker, setSelectedSpeaker] = useState<string>('');
  const [sessionId, setSessionId] = useState<string>('');

  const handleAudioInputComplete = async (data: any, name: string, participants: number, sessionIdFromInput?: string) => {
    setUserName(name);
    setParticipantCount(participants);
    
    if (sessionIdFromInput) {
      setSessionId(sessionIdFromInput);
    }
    
    if (data.inputType === 'recording') {
      setAppState('recording');
    } else {
      // íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ í›„ í™”ìž ë¶„ë¦¬ ì‹œìž‘
      setRecordedData({
        ...data,
        audioFile: data.file // ì—…ë¡œë“œëœ ì›ë³¸ íŒŒì¼ ìœ ì§€
      });
      setProcessingMessage('Analyzing speakers and preparing for selection...');
      setAppState('processing');
      
      try {
        // í™”ìž ë¶„ë¦¬ API í˜¸ì¶œ
        await api.diarizeAudio(sessionIdFromInput!);
        setAppState('speaker-selection');
      } catch (error) {
        console.error('Diarization failed:', error);
        alert(handleApiError(error));
        setAppState('input');
      }
    }
  };

  const handleRecordingComplete = async (data: any) => {
    setRecordedData(data);
    setProcessingMessage('Analyzing speakers and preparing for selection...');
    setAppState('processing');
    
    try {
      // ë…¹ìŒ íŒŒì¼ì´ ìžˆëŠ” ê²½ìš° ì—…ë¡œë“œ ë¨¼ì € ì‹¤í–‰
      if (data.audioFile && data.sessionId) {
        console.log('ðŸ“¤ ë…¹ìŒ íŒŒì¼ ì—…ë¡œë“œ ì‹œìž‘...');
        const uploadResponse = await api.uploadAudio(data.sessionId, data.audioFile);
        console.log('âœ… ì—…ë¡œë“œ ì™„ë£Œ:', uploadResponse);
        
        // ì—…ë¡œë“œ ì™„ë£Œ í›„ í™”ìž ë¶„ë¦¬ ì‹¤í–‰
        console.log('ðŸ”„ í™”ìž ë¶„ë¦¬ ì‹œìž‘...');
        await api.diarizeAudio(data.sessionId);
        console.log('âœ… í™”ìž ë¶„ë¦¬ ì™„ë£Œ');
        
        // ë°ì´í„° ì—…ë°ì´íŠ¸
        setRecordedData({
          ...data,
          uploadResponse: uploadResponse,
          diarizationComplete: true
        });
      }
      
      setAppState('speaker-selection');
    } catch (error) {
      console.error('âŒ Recording processing failed:', error);
      alert(handleApiError(error));
      setAppState('input');
    }
  };

  const handleSpeakerSelected = async (speakerId: string) => {
    setSelectedSpeaker(speakerId);
    setProcessingMessage('Performing final analysis...');
    setAppState('processing');
    
    try {
      // í™”ìž ì„ íƒ API í˜¸ì¶œ
      await api.selectSpeaker(sessionId, speakerId);
      
      // ìŒì„± ë¶„ì„ API í˜¸ì¶œ
      const analysisResult = await api.analyzeAudio(sessionId);
      
      if (analysisResult) {
        // ì‹¤ì œ ë¶„ì„ ê²°ê³¼ê°€ ìžˆëŠ” ê²½ìš°
        setRecordedData({ ...recordedData, analysisResult });
      }
      // nullì¸ ê²½ìš° Mock ë°ì´í„° ì‚¬ìš© (í˜„ìž¬ ìƒí™©)
      
      setAppState('results');
    } catch (error) {
      console.error('Speaker selection or analysis failed:', error);
      alert(handleApiError(error));
      setAppState('speaker-selection');
    }
  };

  const handleStartOver = () => {
    setAppState('input');
    setRecordedData(null);
    setUserName('');
    setParticipantCount(2);
    setSelectedSpeaker('');
    setSessionId('');
  };

  const renderContent = () => {
    switch (appState) {
      case 'input':
        return <AudioInput onComplete={handleAudioInputComplete} />;
      case 'recording':
        return <RecordingInterface onComplete={handleRecordingComplete} onBack={() => setAppState('input')} userName={userName} sessionId={sessionId} />;
      case 'processing':
        return <Processing message={processingMessage} />;
      case 'speaker-selection':
        return <SpeakerSelection audioData={recordedData} userName={userName} participantCount={participantCount} sessionId={sessionId} onSpeakerSelected={handleSpeakerSelected} onBack={() => setAppState('input')} />;
      case 'results':
        return <AnalysisResults data={recordedData} userName={userName} selectedSpeaker={selectedSpeaker} onStartOver={handleStartOver} />;
      default:
        return <AudioInput onComplete={handleAudioInputComplete} />;
    }
  };

  return (
    <div className="min-h-screen bg-white page-container">
      <div className="mx-auto max-w-4xl px-4 py-6 md:py-12">
        <header className="text-center">
          <div className="">
            <img 
              src="/Logo.png" 
              alt="Speakor" 
              className="mx-auto h-[19rem] w-auto"
            />
          </div>
        </header>

        <main className="w-full">
          {renderContent()}
        </main>
      </div>
    </div>
  );
};

export default Index;
