import { useState } from "react";
import { Loader2 } from "lucide-react";
import RecordingInterface from "@/components/RecordingInterface";
import SpeakerSelection from "@/components/SpeakerSelection";
import AnalysisResults from "@/components/AnalysisResults";
import AudioInput from "@/components/AudioInput";
import { api, handleApiError, runFullAnalysis } from "@/utils/api";

type AppState = 'input' | 'recording' | 'processing' | 'speaker-selection' | 'results';

const Processing = ({ message }: { message: string }) => (
  <div className="min-h-screen bg-white page-container">
    <div className="flex flex-col items-center justify-center space-y-6 animate-fade-in text-center min-h-[50vh]">
      <div className="w-20 h-20 bg-blue-50 rounded-full flex items-center justify-center">
        <Loader2 className="w-12 h-12 text-blue-600 animate-spin" />
      </div>
      <p className="text-body text-gray-700">
        {message}
      </p>
    </div>
  </div>
);

const Index = () => {
  const [appState, setAppState] = useState<AppState>('input');
  const [processingMessage, setProcessingMessage] = useState<string>('');
  const [recordedData, setRecordedData] = useState<any>(null);
  const [userName, setUserName] = useState<string>('');
  const [participantCount, setParticipantCount] = useState<number>(2);
  const [selectedSpeaker, setSelectedSpeaker] = useState<string>('');
  const [sessionId, setSessionId] = useState<string>('');
  const [analysisResults, setAnalysisResults] = useState<any>(null);

  const handleAudioInputComplete = async (data: any, name: string, participants: number, sessionIdFromInput?: string) => {
    setUserName(name);
    setParticipantCount(participants);
    
    if (sessionIdFromInput) {
      setSessionId(sessionIdFromInput);
    }
    
    if (data.inputType === 'recording') {
      setAppState('recording');
    } else {
      // íŒŒì¼ ì—…ë¡œë“œ: ì¦‰ì‹œ ë¡œë”© í™”ë©´ìœ¼ë¡œ ì „í™˜
      setProcessingMessage('Uploading file and initializing session...');
      setAppState('processing');
      
      try {
        // ì—…ë¡œë“œ Promise ëŒ€ê¸°
        const uploadResult = await data.uploadPromise;
        
        setSessionId(uploadResult.sessionId);
        setRecordedData({
          ...data,
          audioFile: data.file,
          uploadResponse: uploadResult.uploadResponse,
          sessionId: uploadResult.sessionId
        });
        
        // ì—…ë¡œë“œ ì™„ë£Œ í›„ í™”ìž ë¶„ë¦¬ ì‹œìž‘
        setProcessingMessage('Analyzing speakers and preparing for selection...');
        await api.diarizeAudio(uploadResult.sessionId);
        setAppState('speaker-selection');
        
      } catch (error) {
        console.error('File upload or diarization failed:', error);
        alert(handleApiError(error));
        setAppState('input');
      }
    }
  };

  const handleRecordingComplete = async (data: any) => {
    setRecordedData(data);
    setProcessingMessage('Analyzing speakers and preparing for selection...');
    setAppState('processing');
    
    try {
      // ë…¹ìŒ íŒŒì¼ì´ ìžˆëŠ” ê²½ìš° ì—…ë¡œë“œ ë¨¼ì € ì‹¤í–‰
      if (data.audioFile && data.sessionId) {
        console.log('ðŸ“¤ ë…¹ìŒ íŒŒì¼ ì—…ë¡œë“œ ì‹œìž‘...');
        const uploadResponse = await api.uploadAudio(data.sessionId, data.audioFile);
        console.log('âœ… ì—…ë¡œë“œ ì™„ë£Œ:', uploadResponse);
        
        // ì—…ë¡œë“œ ì™„ë£Œ í›„ í™”ìž ë¶„ë¦¬ ì‹¤í–‰
        console.log('ðŸ”„ í™”ìž ë¶„ë¦¬ ì‹œìž‘...');
        await api.diarizeAudio(data.sessionId);
        console.log('âœ… í™”ìž ë¶„ë¦¬ ì™„ë£Œ');
        
        // ë°ì´í„° ì—…ë°ì´íŠ¸
        setRecordedData({
          ...data,
          uploadResponse: uploadResponse,
          diarizationComplete: true
        });
      }
      
      setAppState('speaker-selection');
    } catch (error) {
      console.error('âŒ Recording processing failed:', error);
      alert(handleApiError(error));
      setAppState('input');
    }
  };

  const handleSpeakerSelected = async (speakerId: string) => {
    setSelectedSpeaker(speakerId);
    setAppState('processing');
    
    try {
      console.log('ðŸŽ¯ í™”ìž ì„ íƒ ì™„ë£Œ, ë¶„ì„ í”Œë¡œìš° ì‹œìž‘:', { speakerId, userName, sessionId });
      
      // 1ë‹¨ê³„: í™”ìž ì„ íƒ API í˜¸ì¶œ
              setProcessingMessage('Selecting speaker and preparing analysis...');
      await api.selectSpeaker(sessionId, speakerId);
      console.log('âœ… í™”ìž ì„ íƒ API ì™„ë£Œ');
      
      // Step 2: Sequential STT â†’ LLM analysis
      const analysisResult = await runFullAnalysis(
        sessionId, 
        speakerId, 
        userName,
        (step, message) => {
          // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì½œë°±
          setProcessingMessage(message);
          console.log(`ðŸ“ˆ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸: ${step} - ${message}`);
        }
      );
      
      console.log('ðŸŽ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ:', analysisResult);
      
      // ë¶„ì„ ê²°ê³¼ ì €ìž¥
      setAnalysisResults(analysisResult);
      setRecordedData({ 
        ...recordedData, 
        analysisResult: analysisResult,
        segments: analysisResult.segments,
        stats: analysisResult.stats
      });
      
      setAppState('results');
      
    } catch (error) {
      console.error('âŒ í™”ìž ì„ íƒ ë˜ëŠ” ë¶„ì„ ì‹¤íŒ¨:', error);
      alert(handleApiError(error));
      setAppState('speaker-selection');
    }
  };

  const handleStartOver = () => {
    setAppState('input');
    setRecordedData(null);
    setUserName('');
    setParticipantCount(2);
    setSelectedSpeaker('');
    setSessionId('');
    setAnalysisResults(null);
  };

  const renderContent = () => {
    switch (appState) {
      case 'input':
        return <AudioInput onComplete={handleAudioInputComplete} />;
      case 'recording':
        return <RecordingInterface onComplete={handleRecordingComplete} onBack={() => setAppState('input')} userName={userName} sessionId={sessionId} />;
      case 'processing':
        return <Processing message={processingMessage} />;
      case 'speaker-selection':
        return <SpeakerSelection audioData={recordedData} userName={userName} participantCount={participantCount} sessionId={sessionId} onSpeakerSelected={handleSpeakerSelected} onBack={() => setAppState('input')} />;
      case 'results':
        return <AnalysisResults data={recordedData} userName={userName} selectedSpeaker={selectedSpeaker} analysisResults={analysisResults} onStartOver={handleStartOver} />;
      default:
        return <AudioInput onComplete={handleAudioInputComplete} />;
    }
  };

  return (
    <div className="min-h-screen bg-white page-container">
      <div className="mx-auto max-w-4xl px-4 py-6 md:py-12">
        <header className="text-center">
          <div className="">
            <img 
              src="/Logo.png" 
              alt="Speakor" 
              className="mx-auto h-[19rem] w-auto"
            />
          </div>
        </header>

        <main className="w-full">
          {renderContent()}
        </main>
      </div>
    </div>
  );
};

export default Index;
